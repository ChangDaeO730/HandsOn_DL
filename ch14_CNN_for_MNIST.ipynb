{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mnist preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(data, valid_nums = 5000):\n",
    "    # train/valid/test split & scaling\n",
    "    (X_train_full, y_train_full), (X_test, y_test) = data\n",
    "    X_train_full = X_train_full / 255.\n",
    "    X_test = X_test / 255.\n",
    "    X_train, X_valid = X_train_full[:-(valid_nums)], X_train_full[-(valid_nums):]\n",
    "    y_train, y_valid = y_train_full[:-(valid_nums)], y_train_full[-(valid_nums):]\n",
    "\n",
    "    # [28*28] -> [28*28*1]\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_valid = X_valid[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def middle_block(x, conv_nums, growth_rate):\n",
    "        for i in range(1, conv_nums+1):\n",
    "            x = layers.Conv2D(growth_rate * (2**i), 3, padding = \"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Activation('relu')(x)\n",
    "            x = layers.Conv2D(growth_rate * (2**i), 3, padding = \"same\")(x)\n",
    "            x = layers.BatchNormalization()(x)\n",
    "            x = layers.Activation('relu')(x)\n",
    "            x = keras.layers.MaxPool2D(2)(x)\n",
    "        return x\n",
    "\n",
    "def create_NN(conv_nums = 3, dropout_rate = 0.3, growth_rate = 32):\n",
    "    \n",
    "    ## Entry Flow\n",
    "    inputs = keras.layers.Input((28, 28, 1))\n",
    "    conv_1 = layers.Conv2D(growth_rate, 5, strides = 2, padding = \"same\")(inputs)\n",
    "    pool_1 = layers.MaxPooling2D(2)(conv_1) \n",
    "    \n",
    "    ## Middle Flow\n",
    "    x = middle_block(pool_1, conv_nums, growth_rate)\n",
    "    \n",
    "    ## Exit Flow\n",
    "    flatten = tf.keras.layers.Flatten()(x)\n",
    "    fc1 = layers.Dense(growth_rate * 4, activation='relu')(flatten)\n",
    "    fc1 = layers.Dropout(dropout_rate)(fc1)\n",
    "    fc2 = layers.Dense(growth_rate * 2, activation='relu')(fc1)\n",
    "    fc2 = layers.Dropout(dropout_rate)(fc2)\n",
    "    outputs = layers.Dense(10, activation='relu')(fc2)\n",
    "    \n",
    "    model = keras.models.Model(inputs = inputs, outputs = outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential API\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss & optimizer define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "mnist = keras.datasets.mnist.load_data()\n",
    "X_train, y_train, X_valid, y_valid, X_test, y_test = preprocessor(data = mnist)\n",
    "\n",
    "# model create\n",
    "model = create_NN(conv_nums = 2)\n",
    "\n",
    "# fit / evaluate\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = \"nadam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
