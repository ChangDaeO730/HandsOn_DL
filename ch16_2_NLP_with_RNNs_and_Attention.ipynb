{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Encoder-Decoder Network for NMT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-addons==0.9.1\n",
      "  Downloading tensorflow_addons-0.9.1-cp37-cp37m-win_amd64.whl (867 kB)\n",
      "Collecting typeguard>=2.7\n",
      "  Downloading typeguard-2.10.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: typeguard, tensorflow-addons\n",
      "Successfully installed tensorflow-addons-0.9.1 typeguard-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-addons==0.9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100\n",
    "embed_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "# inputs\n",
    "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
    "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
    "\n",
    "# embeddings\n",
    "embeddings = keras.layers.Embedding(vocab_size, embed_size)\n",
    "encoder_embeddings = embeddings(encoder_inputs)\n",
    "decoder_embeddings = embeddings(decoder_inputs)\n",
    "\n",
    "# encoder\n",
    "encoder = keras.layers.LSTM(512, return_state=True) # for carrying the last state to decoder\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
    "encoder_state = [state_h, state_c]\n",
    "\n",
    "# decoder\n",
    "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "# sampling from the decoder output distribution \n",
    "# and producing the inputs for the next decoding step.\n",
    "# at Training : previous target token\n",
    "# at Inference : previous prediction token\n",
    "\n",
    "decoder_cell = keras.layers.LSTMCell(512)\n",
    "output_layer = keras.layers.Dense(vocab_size)\n",
    "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell, sampler,\n",
    "                                                 output_layer=output_layer)\n",
    "final_outputs, final_state, final_sequence_lengths = decoder(\n",
    "    decoder_embeddings, initial_state=encoder_state,\n",
    "    sequence_length=sequence_lengths)#, training=None)\n",
    "Y_proba = tf.nn.softmax(final_outputs.rnn_output)\n",
    "\n",
    "model = keras.models.Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs, sequence_lengths],\n",
    "    outputs=[Y_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.random.randint(100, size=10*1000).reshape(1000, 10)\n",
    "# Y = np.random.randint(100, size=15*1000).reshape(1000, 15)\n",
    "# X_decoder = np.c_[np.zeros((1000, 1)), Y[:, :-1]]\n",
    "# seq_lengths = np.full([1000], 15)\n",
    "\n",
    "# history = model.fit([X, X_decoder, seq_lengths], Y, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Bidirectional RNN\n",
    "보통의 순환 층은 과거와 현재의 입력만 보고 출력을 생성한다. (단방향적인 causal model)  \n",
    "이런 종류의 RNN은 시계열 예측시에는 적합하지만, nmt 등의 NLP TASK에는 맞지않음.  \n",
    "단어는 해당 단어가 속한 문장 전체의 문맥에 영향을 받기 때문.\n",
    "<br/><br/>\n",
    "NLP에서 사용되는 RNN은 주로 Bidirectional하게 구현되는데,  \n",
    "방향이 다른 unidirectional 층 2개를 사용하여 각 방향에 대해 학습시키고 concatenate 하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 10)          660       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 20)          1320      \n",
      "=================================================================\n",
      "Total params: 1,980\n",
      "Trainable params: 1,980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 구현은 단지 keras.layers.Bidirectional로 rnn layer를 감싸면 됨\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(10, return_sequences=True, input_shape=[None, 10]),\n",
    "    keras.layers.Bidirectional(keras.layers.GRU(10, return_sequences=True))\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 beam search\n",
    "<br/>\n",
    "decoder의 매 step 출력은 각 스텝에서 확률이 가장 높은 단어들을 출력하는 greedy한 방식이다.  \n",
    "이 방식은 이후의 step까지 고려했을때 더 타당한 잠재적 정답들을 놓칠 수 있는 위험이 있다.\n",
    "따라서 계산 리소스는 더 사용하나, 이런 위험을 피할 수 있는 search 알고리즘을 사용한다.  \n",
    "<br/><br/>\n",
    "모든 가능한 경우를 계산하는 exhaustive search는 안정적인 해답을 찾지만 계산량이 말도안된다.  \n",
    "대신 실용적인 beam search가 널리 사용된다.\n",
    "<img src = \"https://d2l.ai/_images/beam-search.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_width = 10\n",
    "decoder = tfa.seq2seq.beam_search_decoder.BeamSearchDecoder(\n",
    "    cell = decoder_cell, beam_width = beam_width, output_layer = output_layer)\n",
    "decoder_initial_state = tfa.seq2seq.beam_search_decoder.tile_batch(\n",
    "    encoder_state, multiplier = beam_width)\n",
    "outputs, _, _ = decoder(\n",
    "    embedding_decoder, start_tokens = start_tokens, end_token = end_token,\n",
    "    initial_state = decoder_initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
